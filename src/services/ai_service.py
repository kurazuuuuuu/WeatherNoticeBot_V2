"""
Google Gemini AIã‚’ä½¿ç”¨ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å¤©æ°—æƒ…å ±ã«åŸºã¥ã„ã¦ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import asyncio
import logging
import time
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from datetime import datetime

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from google.api_core import exceptions as google_exceptions

try:
    from ..config import Config
except ImportError:
    from src.config import Config


@dataclass
class WeatherContext:
    """å¤©æ°—æƒ…å ±ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
    area_name: str
    weather_description: str
    temperature: Optional[float]
    precipitation_probability: int
    wind: str
    timestamp: datetime
    is_alert: bool = False
    alert_description: Optional[str] = None


def weather_data_to_context(weather_data) -> WeatherContext:
    """
    WeatherDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’WeatherContextã«å¤‰æ›
    
    Args:
        weather_data: WeatherDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆweather_serviceã‹ã‚‰ï¼‰
    
    Returns:
        WeatherContext: AIã‚µãƒ¼ãƒ“ã‚¹ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    """
    return WeatherContext(
        area_name=weather_data.area_name,
        weather_description=weather_data.weather_description,
        temperature=weather_data.temperature,
        precipitation_probability=weather_data.precipitation_probability,
        wind=weather_data.wind,
        timestamp=weather_data.timestamp,
        is_alert=False,  # è­¦å ±æƒ…å ±ã¯åˆ¥é€”è¨­å®š
        alert_description=None
    )


class AIServiceError(Exception):
    """AI ã‚µãƒ¼ãƒ“ã‚¹é–¢é€£ã®ã‚¨ãƒ©ãƒ¼"""
    pass


class AIServiceRateLimitError(AIServiceError):
    """AI ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼"""
    pass


class AIServiceQuotaExceededError(AIServiceError):
    """AI ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¯ã‚©ãƒ¼ã‚¿è¶…éã‚¨ãƒ©ãƒ¼"""
    pass


class AIMessageService:
    """Google Gemini AIã‚’ä½¿ç”¨ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹"""
    
    # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
    MAX_RETRIES = 3
    RETRY_DELAY = 2.0  # ç§’
    BACKOFF_FACTOR = 2.0
    MAX_RETRY_DELAY = 30.0  # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤é–“éš”
    
    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®š
    RATE_LIMIT_WINDOW = 60  # 1åˆ†é–“ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
    MAX_REQUESTS_PER_MINUTE = 15  # 1åˆ†é–“ã®æœ€å¤§ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
    
    def __init__(self, config: Config = None):
        if config is None:
            from src.config import config as default_config
            config = default_config
        self.config = config
        self.logger = logging.getLogger(__name__)
        self._client = None
        self._model = None
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ç®¡ç†
        self._request_times: List[float] = []
        self._last_request_time = 0.0
        
        # ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç®¡ç†
        self._is_available = True
        self._last_error_time = 0.0
        self._consecutive_errors = 0
        self._circuit_breaker_timeout = 300  # 5åˆ†é–“ã®ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼
        
        self._initialize_client()
    
    def _initialize_client(self) -> None:
        """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            if not self.config.GEMINI_API_KEY:
                self.logger.warning("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                self._is_available = False
                return
            
            genai.configure(api_key=self.config.GEMINI_API_KEY)
            
            # å®‰å…¨è¨­å®šã‚’æ§‹æˆ
            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
            
            # ç”Ÿæˆè¨­å®š
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 200,
            }
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
            self._model = genai.GenerativeModel(
                model_name='gemini-1.5-flash',
                safety_settings=safety_settings,
                generation_config=generation_config
            )
            
            self._is_available = True
            self._consecutive_errors = 0
            self.logger.info("Gemini AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
            
        except Exception as e:
            self.logger.error(f"Gemini AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            self._model = None
            self._is_available = False
    
    def _check_circuit_breaker(self) -> bool:
        """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        
        # é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã„å ´åˆã€ä¸€å®šæ™‚é–“ã‚µãƒ¼ãƒ“ã‚¹ã‚’åœæ­¢
        if self._consecutive_errors >= 5:
            if current_time - self._last_error_time < self._circuit_breaker_timeout:
                return False
            else:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¾Œã€ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
                self._consecutive_errors = 0
                self.logger.info("AIã‚µãƒ¼ãƒ“ã‚¹ã®ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
        
        return True
    
    def _check_rate_limit(self) -> None:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        
        # å¤ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚åˆ»ã‚’å‰Šé™¤
        self._request_times = [
            req_time for req_time in self._request_times
            if current_time - req_time < self.RATE_LIMIT_WINDOW
        ]
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(self._request_times) >= self.MAX_REQUESTS_PER_MINUTE:
            raise AIServiceRateLimitError(
                f"AIã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{self.RATE_LIMIT_WINDOW}ç§’å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
            )
        
        # ç¾åœ¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚åˆ»ã‚’è¨˜éŒ²
        self._request_times.append(current_time)
        self._last_request_time = current_time
    
    def _handle_api_error(self, error: Exception) -> None:
        """APIã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†"""
        current_time = time.time()
        self._last_error_time = current_time
        self._consecutive_errors += 1
        
        # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã«å¿œã˜ã¦å‡¦ç†
        if isinstance(error, google_exceptions.ResourceExhausted):
            self.logger.warning("Gemini APIã®ã‚¯ã‚©ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            raise AIServiceQuotaExceededError("APIã‚¯ã‚©ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        elif isinstance(error, google_exceptions.TooManyRequests):
            self.logger.warning("Gemini APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ")
            raise AIServiceRateLimitError("APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ")
        elif isinstance(error, google_exceptions.DeadlineExceeded):
            self.logger.warning("Gemini APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            raise AIServiceError("APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        elif isinstance(error, google_exceptions.ServiceUnavailable):
            self.logger.warning("Gemini APIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            raise AIServiceError("APIã‚µãƒ¼ãƒ“ã‚¹ãŒä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“")
        else:
            self.logger.error(f"Gemini APIäºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {error}")
            raise AIServiceError(f"äºˆæœŸã—ãªã„APIã‚¨ãƒ©ãƒ¼: {str(error)}")
    
    def _reset_error_count(self) -> None:
        """ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ"""
        if self._consecutive_errors > 0:
            self._consecutive_errors = 0
            self.logger.info("AIã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    async def generate_positive_message(
        self, 
        weather_context: WeatherContext,
        message_type: str = "general",
        retries: int = 0
    ) -> str:
        """
        å¤©æ°—æƒ…å ±ã«åŸºã¥ã„ã¦ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        
        Args:
            weather_context: å¤©æ°—æƒ…å ±ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            message_type: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ï¼ˆgeneral, morning, evening, alertï¼‰
            retries: ç¾åœ¨ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°
        
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        # ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
        if not self._check_circuit_breaker():
            self.logger.warning("AIã‚µãƒ¼ãƒ“ã‚¹ã®ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãŒé–‹ã„ã¦ã„ã¾ã™ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._get_fallback_message(weather_context, message_type)
        
        if not self._model or not self._is_available:
            return self._get_fallback_message(weather_context, message_type)
        
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
            self._check_rate_limit()
            
            prompt = self._create_prompt(weather_context, message_type)
            
            # éåŒæœŸã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
            response = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: self._model.generate_content(prompt)
                ),
                timeout=30.0  # 30ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            if response and response.text:
                generated_message = response.text.strip()
                self.logger.info(f"AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ: {len(generated_message)}æ–‡å­—")
                
                # æˆåŠŸæ™‚ã¯ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
                self._reset_error_count()
                
                return generated_message
            else:
                self.logger.warning("AIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return self._get_fallback_message(weather_context, message_type)
                
        except asyncio.TimeoutError:
            self.logger.warning("AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”ŸæˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._get_fallback_message(weather_context, message_type)
            
        except (AIServiceRateLimitError, AIServiceQuotaExceededError) as e:
            self.logger.warning(f"AI ã‚µãƒ¼ãƒ“ã‚¹åˆ¶é™ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã¯ãƒªãƒˆãƒ©ã‚¤
            if isinstance(e, AIServiceRateLimitError) and retries < self.MAX_RETRIES:
                delay = min(self.RETRY_DELAY * (self.BACKOFF_FACTOR ** retries), self.MAX_RETRY_DELAY)
                self.logger.info(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ ({retries + 1}/{self.MAX_RETRIES}) - {delay}ç§’å¾Œ")
                await asyncio.sleep(delay)
                return await self.generate_positive_message(weather_context, message_type, retries + 1)
            
            return self._get_fallback_message(weather_context, message_type)
            
        except AIServiceError as e:
            self.logger.warning(f"AI ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒªãƒˆãƒ©ã‚¤
            if retries < self.MAX_RETRIES and "ä¸€æ™‚çš„" in str(e):
                delay = min(self.RETRY_DELAY * (self.BACKOFF_FACTOR ** retries), self.MAX_RETRY_DELAY)
                self.logger.info(f"ä¸€æ™‚çš„ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ ({retries + 1}/{self.MAX_RETRIES}) - {delay}ç§’å¾Œ")
                await asyncio.sleep(delay)
                return await self.generate_positive_message(weather_context, message_type, retries + 1)
            
            return self._get_fallback_message(weather_context, message_type)
            
        except Exception as e:
            try:
                self._handle_api_error(e)
            except (AIServiceRateLimitError, AIServiceQuotaExceededError, AIServiceError):
                pass  # æ—¢ã«ãƒ­ã‚°å‡ºåŠ›æ¸ˆã¿
            
            # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ãƒªãƒˆãƒ©ã‚¤
            if retries < self.MAX_RETRIES:
                delay = min(self.RETRY_DELAY * (self.BACKOFF_FACTOR ** retries), self.MAX_RETRY_DELAY)
                self.logger.info(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ ({retries + 1}/{self.MAX_RETRIES}) - {delay}ç§’å¾Œ")
                await asyncio.sleep(delay)
                return await self.generate_positive_message(weather_context, message_type, retries + 1)
            
            return self._get_fallback_message(weather_context, message_type)
    
    def _create_prompt(self, weather_context: WeatherContext, message_type: str) -> str:
        """AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        base_prompt = f"""
ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„å¤©æ°—äºˆå ±ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å¤©æ°—æƒ…å ±ã«åŸºã¥ã„ã¦ã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’åŠ±ã¾ã—ã€å‰å‘ããªæ°—æŒã¡ã«ã•ã›ã‚‹çŸ­ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å¤©æ°—æƒ…å ±:
- åœ°åŸŸ: {weather_context.area_name}
- å¤©æ°—: {weather_context.weather_description}
- æ°—æ¸©: {weather_context.temperature}Â°C (æƒ…å ±ãŒã‚ã‚‹å ´åˆ)
- é™æ°´ç¢ºç‡: {weather_context.precipitation_probability}%
- é¢¨: {weather_context.wind}
- æ™‚åˆ»: {weather_context.timestamp.strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚')}
"""
        
        if weather_context.is_alert and weather_context.alert_description:
            base_prompt += f"\n- æ°—è±¡è­¦å ±: {weather_context.alert_description}"
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª¿æ•´
        if message_type == "morning":
            base_prompt += "\n\næœã®æŒ¨æ‹¶ã¨ã—ã¦ã€ä»Šæ—¥ä¸€æ—¥ã‚’å‰å‘ãã«éã”ã›ã‚‹ã‚ˆã†ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        elif message_type == "evening":
            base_prompt += "\n\nå¤•æ–¹ã®æŒ¨æ‹¶ã¨ã—ã¦ã€ä¸€æ—¥ãŠç–²ã‚Œæ§˜ã®æ°—æŒã¡ã‚’è¾¼ã‚ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        elif message_type == "alert":
            base_prompt += "\n\næ°—è±¡è­¦å ±ãŒå‡ºã¦ã„ã¾ã™ãŒã€å®‰å…¨ã«éã”ã™ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¨åŠ±ã¾ã—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        else:
            base_prompt += "\n\nå¤©æ°—ã«é–¢é€£ã—ãŸå‰å‘ãã§åŠ±ã¾ã—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        
        base_prompt += """

è¦ä»¶:
- 100æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«
- è¦ªã—ã¿ã‚„ã™ãæ¸©ã‹ã„å£èª¿ã§
- å¤©æ°—ã«å¿œã˜ãŸå…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„åŠ±ã¾ã—ã‚’å«ã‚ã‚‹
- çµµæ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨ã—ã¦è¦ªã—ã¿ã‚„ã™ã•ã‚’æ¼”å‡º
- ãƒã‚¬ãƒ†ã‚£ãƒ–ãªè¡¨ç¾ã¯é¿ã‘ã€å¸¸ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¦–ç‚¹ã§
"""
        
        return base_prompt
    
    def _get_fallback_message(
        self, 
        weather_context: WeatherContext, 
        message_type: str
    ) -> str:
        """AIãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
        
        # æ°—è±¡è­¦å ±ãŒã‚ã‚‹å ´åˆã®ç‰¹åˆ¥ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if weather_context.is_alert:
            return f"âš ï¸ {weather_context.area_name}ã«æ°—è±¡è­¦å ±ãŒç™ºè¡¨ã•ã‚Œã¦ã„ã¾ã™ã€‚å®‰å…¨ç¬¬ä¸€ã§éã”ã—ã¦ãã ã•ã„ã­ï¼ ğŸ™"
        
        # é™æ°´ç¢ºç‡ã«åŸºã¥ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if weather_context.precipitation_probability >= 70:
            messages = [
                f"â˜” {weather_context.area_name}ã¯é›¨ã®äºˆå ±ã§ã™ãŒã€é›¨éŸ³ã‚’èããªãŒã‚‰ã‚†ã£ãã‚Šéã”ã™ã®ã‚‚ç´ æ•µã§ã™ã­ï¼ ğŸŒ§ï¸âœ¨",
                f"ğŸŒ‚ é›¨ã®æ—¥ã¯èª­æ›¸ã‚„æ˜ ç”»é‘‘è³ã«ã´ã£ãŸã‚Šï¼{weather_context.area_name}ã§ã®ç´ æ•µãªæ™‚é–“ã‚’ãŠéã”ã—ãã ã•ã„ ğŸ“š",
                f"â˜” é›¨ã®{weather_context.area_name}ã‚‚ç¾ã—ã„ã‚‚ã®ã€‚å‚˜ã‚’å¿˜ã‚Œãšã«ã€å®‰å…¨ã«ãŠå‡ºã‹ã‘ãã ã•ã„ã­ï¼ ğŸŒˆ"
            ]
        elif weather_context.precipitation_probability >= 30:
            messages = [
                f"ğŸŒ¤ï¸ {weather_context.area_name}ã¯å°‘ã—é›²ãŒå¤šã‚ã§ã™ãŒã€ãã£ã¨ç´ æ•µãªä¸€æ—¥ã«ãªã‚Šã¾ã™ã‚ˆï¼ â˜ï¸âœ¨",
                f"â›… æ›‡ã‚Šç©ºã®{weather_context.area_name}ã‚‚è¶£ãŒã‚ã£ã¦è‰¯ã„ã§ã™ã­ã€‚ä»Šæ—¥ã‚‚é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼ ğŸ’ª",
                f"ğŸŒ¥ï¸ ãŠå¤©æ°—ã¯å¤‰ã‚ã‚Šã‚„ã™ãã†ã§ã™ãŒã€{weather_context.area_name}ã§ã®ä¸€æ—¥ã‚’æ¥½ã—ã‚“ã§ãã ã•ã„ã­ï¼ ğŸŒŸ"
            ]
        else:
            messages = [
                f"â˜€ï¸ {weather_context.area_name}ã¯è‰¯ã„ãŠå¤©æ°—ï¼ä»Šæ—¥ã‚‚ç´ æ™´ã‚‰ã—ã„ä¸€æ—¥ã«ãªã‚Šãã†ã§ã™ã­ï¼ ğŸŒŸ",
                f"ğŸŒ æ™´ã‚Œã®{weather_context.area_name}ã§ã€ãã£ã¨æ°—åˆ†ã‚‚æ™´ã‚Œã‚„ã‹ã«ãªã‚Šã¾ã™ã‚ˆï¼ âœ¨",
                f"â˜€ï¸ é’ç©ºã®{weather_context.area_name}ï¼å¤–ã«å‡ºã‹ã‘ã‚‹ã®ã«ã´ã£ãŸã‚Šã®æ—¥ã§ã™ã­ï¼ ğŸš¶â€â™€ï¸"
            ]
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦èª¿æ•´
        if message_type == "morning":
            prefix = "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼ "
        elif message_type == "evening":
            prefix = "ãŠç–²ã‚Œæ§˜ã§ã™ï¼ "
        else:
            prefix = ""
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é¸æŠï¼ˆå®Ÿéš›ã«ã¯ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ã§ä¸€è²«æ€§ã‚’ä¿ã¤ï¼‰
        import hashlib
        hash_input = f"{weather_context.area_name}{weather_context.timestamp.date()}"
        hash_value = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)
        selected_message = messages[hash_value % len(messages)]
        
        return prefix + selected_message
    
    async def generate_weather_summary_message(
        self, 
        weather_context: WeatherContext,
        forecast_days: int = 3
    ) -> str:
        """
        å¤©æ°—äºˆå ±ã®è¦ç´„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        
        Args:
            weather_context: å¤©æ°—æƒ…å ±ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            forecast_days: äºˆå ±æ—¥æ•°
        
        Returns:
            è¦ç´„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        if not self._model:
            return self._get_summary_fallback_message(weather_context)
        
        try:
            prompt = f"""
ä»¥ä¸‹ã®å¤©æ°—æƒ…å ±ã‚’åŸºã«ã€{forecast_days}æ—¥é–“ã®å¤©æ°—ã®å‚¾å‘ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

åœ°åŸŸ: {weather_context.area_name}
ç¾åœ¨ã®å¤©æ°—: {weather_context.weather_description}
æ°—æ¸©: {weather_context.temperature}Â°C
é™æ°´ç¢ºç‡: {weather_context.precipitation_probability}%

50æ–‡å­—ä»¥å†…ã§ã€ä»Šå¾Œã®å¤©æ°—ã®å‚¾å‘ã¨éã”ã—æ–¹ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§ã€çµµæ–‡å­—ã‚‚ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
"""
            
            response = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: self._model.generate_content(prompt)
            )
            
            if response and response.text:
                return response.text.strip()
            else:
                return self._get_summary_fallback_message(weather_context)
                
        except Exception as e:
            self.logger.error(f"è¦ç´„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return self._get_summary_fallback_message(weather_context)
    
    def _get_summary_fallback_message(self, weather_context: WeatherContext) -> str:
        """è¦ç´„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if weather_context.precipitation_probability >= 50:
            return f"ğŸŒ§ï¸ {weather_context.area_name}ã¯é›¨ã®å¯èƒ½æ€§ãŒé«˜ã‚ã§ã™ã€‚å‚˜ã®æº–å‚™ã‚’ãŠå¿˜ã‚Œãªãï¼"
        else:
            return f"â˜€ï¸ {weather_context.area_name}ã¯æ¯”è¼ƒçš„è‰¯ã„ãŠå¤©æ°—ãŒç¶šããã†ã§ã™ï¼"
    
    def is_available(self) -> bool:
        """AIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹ã‚’ç¢ºèª"""
        return self._model is not None and self._is_available and self._check_circuit_breaker()
    
    async def health_check(self) -> Dict[str, Any]:
        """AIã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        if not self._model:
            return {
                "status": "unavailable",
                "message": "Gemini APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                "fallback_available": True,
                "consecutive_errors": self._consecutive_errors,
                "circuit_breaker_active": not self._check_circuit_breaker()
            }
        
        if not self._check_circuit_breaker():
            return {
                "status": "circuit_breaker_open",
                "message": "ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãŒé–‹ã„ã¦ã„ã¾ã™ï¼ˆé€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šç™ºï¼‰",
                "fallback_available": True,
                "consecutive_errors": self._consecutive_errors,
                "circuit_breaker_active": True
            }
        
        try:
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
            test_context = WeatherContext(
                area_name="ãƒ†ã‚¹ãƒˆåœ°åŸŸ",
                weather_description="æ™´ã‚Œ",
                temperature=20.0,
                precipitation_probability=10,
                wind="åŒ—ã®é¢¨",
                timestamp=datetime.now()
            )
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ãè¨­å®šã—ã¦ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            start_time = time.time()
            test_message = await asyncio.wait_for(
                self.generate_positive_message(test_context),
                timeout=10.0
            )
            response_time = time.time() - start_time
            
            return {
                "status": "available",
                "message": "Gemini AIã‚µãƒ¼ãƒ“ã‚¹ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™",
                "test_message_length": len(test_message),
                "response_time_seconds": round(response_time, 2),
                "fallback_available": True,
                "consecutive_errors": self._consecutive_errors,
                "circuit_breaker_active": False,
                "requests_in_last_minute": len(self._request_times)
            }
            
        except asyncio.TimeoutError:
            return {
                "status": "timeout",
                "message": "Gemini AIã‚µãƒ¼ãƒ“ã‚¹ã®å¿œç­”ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ",
                "fallback_available": True,
                "consecutive_errors": self._consecutive_errors,
                "circuit_breaker_active": False
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"Gemini AIã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "fallback_available": True,
                "consecutive_errors": self._consecutive_errors,
                "circuit_breaker_active": not self._check_circuit_breaker()
            }
    
    def get_service_stats(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        current_time = time.time()
        
        # éå»1åˆ†é–“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’è¨ˆç®—
        recent_requests = [
            req_time for req_time in self._request_times
            if current_time - req_time < self.RATE_LIMIT_WINDOW
        ]
        
        return {
            "is_available": self.is_available(),
            "consecutive_errors": self._consecutive_errors,
            "last_error_time": self._last_error_time,
            "circuit_breaker_active": not self._check_circuit_breaker(),
            "requests_in_last_minute": len(recent_requests),
            "rate_limit_remaining": max(0, self.MAX_REQUESTS_PER_MINUTE - len(recent_requests)),
            "last_request_time": self._last_request_time
        }